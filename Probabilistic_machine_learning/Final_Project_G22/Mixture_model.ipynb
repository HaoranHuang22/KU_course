{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torchvision.datasets as datasets\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torchvision import datasets, transforms\n",
    "import torch.distributions as tdist\n",
    "import scipy.stats as st\n",
    "from scipy.special import logsumexp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([1.0,2.0,3,4,5,6,7,8,9])\n",
    "b = torch.tensor([0.0,0,0,4,5,6,0,0,0])\n",
    "x = torch.rand(784)\n",
    "c = torch.rand(2, 784,784)\n",
    "\n",
    "# t1 = st.multivariate_normal(a,8)\n",
    "# t2 = tdist.MultivariateNormal(a, torch.diag_embed(b))\n",
    "# print(t1.logpdf(x), t2.log_prob(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get train and test data\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=True, download=True,\n",
    "                   transform=transforms.ToTensor()),\n",
    "    batch_size=128, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=False, transform=transforms.ToTensor()),\n",
    "    batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca(data, out_dim=10):\n",
    "    data = data.view(-1,784)\n",
    "    data_mean = data.mean(0)\n",
    "    Q = (data-data_mean).T@(data-data_mean)\n",
    "    U, S, V = torch.svd(Q)\n",
    "    data = data @ U[torch.argsort(S,descending=True)[:out_dim]].T\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GMM():\n",
    "    def __init__(self, latentspace, input_space=784):\n",
    "        super().__init__()\n",
    "        self.C = latentspace\n",
    "        self.N = input_space\n",
    "        self.pi = None\n",
    "        self.mu = []\n",
    "        self.cov = []\n",
    "\n",
    "    def init(self):\n",
    "        x = torch.rand(self.C)\n",
    "        self.pi = x/x.sum()\n",
    "        for i in range(self.C):\n",
    "            self.mu.append(torch.rand(self.N))\n",
    "            self.cov.append(torch.diag_embed(torch.rand(self.N)))\n",
    "\n",
    "    def e_stemp(self, data):\n",
    "        gamma = []\n",
    "        for k in range(self.C):\n",
    "            pdf = st.multivariate_normal(self.mu[k], self.cov[k])\n",
    "            gamma.append(torch.log(self.pi[k]) + pdf.logpdf(data))\n",
    "        gamma = torch.stack(gamma)\n",
    "        gamma_z = torch.exp(gamma-torch.logsumexp(gamma, axis=0))\n",
    "        torch.testing.assert_close(\n",
    "            gamma_z.sum(), torch.tensor(data.shape[0], dtype=gamma_z.dtype))\n",
    "        return gamma_z\n",
    "\n",
    "    def m_step(self, data, gamma_z):\n",
    "        N_k = gamma_z.sum(1)\n",
    "        log_mu = (torch.log(gamma_z).unsqueeze(\n",
    "            2) + torch.log(data.unsqueeze(0))).logsumexp(dim=1) - N_k.unsqueeze(1)\n",
    "        \n",
    "        self.mu = torch.exp(log_mu)\n",
    "        self.cov = torch.exp(torch.logsumexp(torch.log(gamma_z).view(self.C, data.shape[0], 1, 1)+torch.log(torch.einsum(\n",
    "            'ijk, ijg -> ijkg', data-self.mu.unsqueeze(1), data-self.mu.unsqueeze(1))), dim=1) - N_k.view(-1, 1, 1))+1e-4*torch.eye(self.N)\n",
    "  \n",
    "        # self.cov = (((data-self.mu.unsqueeze(1))**2 * gamma_z.unsqueeze(2)).sum(1))/N_k.unsqueeze(1)+1e-4\n",
    "\n",
    "\n",
    "        self.pi = N_k/N_k.sum()\n",
    "\n",
    "        # for k in range(self.C):\n",
    "        #     # self.mu[k] = (gamma_z[k]*data.T).sum(1)/N_k[k]\n",
    "        #     # self.cov[k] = torch.exp(torch.log(gamma_z[k].reshape(data.shape[0], 1, 1))+torch.log(torch.einsum(\n",
    "        #     #     'ij, il -> ijl', (data - self.mu[k]), (data - self.mu[k])))-torch.log(N_k[k])).sum(0)\n",
    "        #     # self.pi[k] = N_k[k]/N_k.sum()\n",
    "        #     temp_mu = 0\n",
    "        #     for n, d in enumerate(data):\n",
    "        #         temp_mu += gamma_z[k][n]*d\n",
    "        #         assert not torch.isnan(\n",
    "        #             gamma_z[k][n]*d).any(), print(gamma_z[k][n]*d)\n",
    "        #     self.mu[k] = temp_mu/N_k[k]\n",
    "        #     assert not torch.isnan(self.mu[k]).any(), print(self.mu[k])\n",
    "        #     temp_cov = 0\n",
    "        #     for n, d in enumerate(data):\n",
    "        #         temp_cov += gamma_z[k][n] * \\\n",
    "        #             torch.outer(d-self.mu[k], d-self.mu[k])\n",
    "        #     self.cov[k] = temp_cov/N_k[k]\n",
    "        #     self.pi[k] = N_k[k]/N_k.sum()\n",
    "\n",
    "    def log_likelihood(self, data):\n",
    "        gamma = []\n",
    "        for k in range(self.C):\n",
    "            pdf = st.multivariate_normal(self.mu[k], self.cov[k])\n",
    "            gamma.append(torch.log(self.pi[k]) + pdf.logpdf(data))\n",
    "        gamma = torch.stack(gamma).flatten(0)\n",
    "        return torch.logsumexp(gamma, dim=0)\n",
    "\n",
    "    def fit(self, data):\n",
    "        gamma_z = self.e_stemp(data)\n",
    "        self.m_step(data, gamma_z)\n",
    "        return self.log_likelihood(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :  0   likelihood :  37.24530428935217\n",
      "epoch :  1   likelihood :  40.023783720592206\n",
      "epoch :  2   likelihood :  38.5708325029266\n",
      "epoch :  3   likelihood :  40.0139915135312\n",
      "epoch :  4   likelihood :  34.28838873428781\n",
      "epoch :  5   likelihood :  40.10558142627226\n",
      "epoch :  6   likelihood :  38.309020173636625\n",
      "epoch :  7   likelihood :  37.35500464891938\n",
      "epoch :  8   likelihood :  39.9635536575236\n",
      "epoch :  9   likelihood :  40.030559973814235\n"
     ]
    }
   ],
   "source": [
    "gmm = GMM(2,10)\n",
    "gmm.init()\n",
    "with torch.no_grad():\n",
    "    for i in range(10):\n",
    "        ll_list = []\n",
    "        for j,(data,_) in enumerate(train_loader):\n",
    "            data = pca(data,10)+1e-4\n",
    "            ll = gmm.fit(data)\n",
    "            ll_list.append(ll)\n",
    "        print(\"epoch : \",i,  \"  likelihood : \", np.mean(ll_list))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7 (default, Sep  3 2021, 12:37:55) \n[Clang 12.0.5 (clang-1205.0.22.9)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
